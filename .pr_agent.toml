[config]
model = "ollama/deepseek-coder-v2:16b"
model_turbo = "ollama/deepseek-coder-v2:16b"
fallback_models=["ollama/deepseek-coder-v2:16b"]
custom_model_max_tokens=128000
